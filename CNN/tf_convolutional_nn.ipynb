{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# TensorFlow: Convolutional NN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "**Components Of The Model**\n",
    "\n",
    "* Model Function (`cnn_model_fn`)\n",
    "    - accept features, class labels, mode and model params as args\n",
    "    - define the layers\n",
    "    - define a dictionary for output of predictions\n",
    "    - create `EstimatorSpec` object for the appropriate mode\n",
    "        + train, predict, eval\n",
    "        + create one-hot from class labels for train and eval\n",
    "        + eval needs dict of metrics to use\n",
    "* Main Function (`main`)\n",
    "    - accept mode and model params as args\n",
    "    - call a function to get data\n",
    "        + load MNIST from TF in this case\n",
    "    - create the estimator with `cnn_model_fn` and model params\n",
    "    - create `*_input_fn` where `*` is the mode (e.g. train)\n",
    "        + uses `numpy_input_fn` from the TF API for numpy data\n",
    "    - run the classifier/estimator using the appropriate mode\n",
    "    - perform any work necessary to display or return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "tf.logging.set_verbosity(tf.logging.INFO)\n",
    "\n",
    "\n",
    "## Model Function\n",
    "def cnn_model_fn(features, labels, mode, params):\n",
    "    \"\"\"Model function for CNN.\"\"\"\n",
    "    # Input Layer\n",
    "    # Reshape X to 4-D tensor: [batch_size, width, height, channels]\n",
    "    # MNIST images are 28x28 pixels, and have one color channel\n",
    "    input_layer = tf.reshape(features[\"x\"], [-1, 28, 28, 1])\n",
    "\n",
    "    # Computes 32 features using a 5x5 filter with ReLU activation\n",
    "    # Input Tensor Shape: [batch_size, 28, 28, 1]\n",
    "    # Output Tensor Shape: [batch_size, 28, 28, 32]\n",
    "    conv1 = tf.layers.conv2d(\n",
    "        inputs=input_layer,\n",
    "        filters=32,\n",
    "        kernel_size=[5, 5],\n",
    "        padding=\"same\",  # use \"valid\" to not preserve WxH\n",
    "        activation=tf.nn.relu)\n",
    "\n",
    "    # First max pooling layer with a 2x2 filter and stride of 2\n",
    "    # Input Tensor Shape: [batch_size, 28, 28, 32]\n",
    "    # Output Tensor Shape: [batch_size, 14, 14, 32]\n",
    "    pool1 = tf.layers.max_pooling2d(inputs=conv1, pool_size=[2, 2], strides=2)\n",
    "\n",
    "    # Computes 64 feature maps using a 5x5 filter.\n",
    "    # Input Tensor Shape: [batch_size, 14, 14, 32]\n",
    "    # Output Tensor Shape: [batch_size, 14, 14, 64]\n",
    "    conv2 = tf.layers.conv2d(\n",
    "        inputs=pool1,\n",
    "        filters=64,\n",
    "        kernel_size=[5, 5],\n",
    "        padding=\"same\",\n",
    "        activation=tf.nn.relu)\n",
    "\n",
    "    # Input Tensor Shape: [batch_size, 14, 14, 64]\n",
    "    # Output Tensor Shape: [batch_size, 7, 7, 64]\n",
    "    pool2 = tf.layers.max_pooling2d(inputs=conv2, pool_size=[2, 2], strides=2)\n",
    "\n",
    "    # Flatten tensor into a batch of vectors for input to dense layer\n",
    "    pool2_flat = tf.reshape(pool2, [-1, 7 * 7 * 64])\n",
    "\n",
    "    # Input Tensor Shape: [batch_size, 7 * 7 * 64]\n",
    "    # Output Tensor Shape: [batch_size, 1024]\n",
    "    dense = tf.layers.dense(inputs=pool2_flat, units=1024, activation=tf.nn.relu)\n",
    "\n",
    "    # Add dropout operation; 0.6 probability that element will be kept\n",
    "    dropout = tf.layers.dropout(\n",
    "        inputs=dense, rate=0.4, training=mode == tf.estimator.ModeKeys.TRAIN)\n",
    "\n",
    "    # Logits layer\n",
    "    # Input Tensor Shape: [batch_size, 1024]\n",
    "    # Output Tensor Shape: [batch_size, 10]\n",
    "    logits = tf.layers.dense(inputs=dropout, units=10)\n",
    "\n",
    "    # this dict will be returned for predictions\n",
    "    predictions = {\n",
    "        # actual class predictions\n",
    "        \"classes\": tf.argmax(input=logits, axis=1),\n",
    "        # class probabilities from softmax on logits\n",
    "        \"probabilities\": tf.nn.softmax(logits, name=\"softmax_tensor\")\n",
    "    }\n",
    "    \n",
    "    if mode == tf.estimator.ModeKeys.PREDICT:\n",
    "        return tf.estimator.EstimatorSpec(mode=mode, predictions=predictions)\n",
    "\n",
    "    # Calculate loss (for both TRAIN and EVAL modes)\n",
    "    onehot_labels = tf.one_hot(indices=tf.cast(labels, tf.int32), depth=10)\n",
    "    loss = tf.losses.softmax_cross_entropy(\n",
    "        onehot_labels=onehot_labels, logits=logits)\n",
    "\n",
    "    # Configure the training Op (for TRAIN mode)\n",
    "    if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "        optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.001)\n",
    "        train_op = optimizer.minimize(\n",
    "            loss=loss,\n",
    "            global_step=tf.train.get_global_step())\n",
    "        return tf.estimator.EstimatorSpec(mode=mode, loss=loss, train_op=train_op)\n",
    "\n",
    "    # evaluation metrics (for EVAL mode)\n",
    "    eval_metric_ops = {\n",
    "        \"accuracy\": tf.metrics.accuracy(\n",
    "            labels=labels, predictions=predictions[\"classes\"])}\n",
    "    return tf.estimator.EstimatorSpec(\n",
    "        mode=mode, loss=loss, eval_metric_ops=eval_metric_ops)\n",
    "    \n",
    "\n",
    "\n",
    "## Main Function\n",
    "def main(mode='train', model_params={'learning_rate': 0.001}):\n",
    "    # Load training and eval data\n",
    "    mnist = tf.contrib.learn.datasets.load_dataset(\"mnist\")\n",
    "    train_data = mnist.train.images  # Returns np.array\n",
    "    train_labels = np.asarray(mnist.train.labels, dtype=np.int32)\n",
    "    eval_data = mnist.test.images  # Returns np.array\n",
    "    eval_labels = np.asarray(mnist.test.labels, dtype=np.int32)\n",
    "\n",
    "    # Create the Estimator\n",
    "    mnist_classifier = tf.estimator.Estimator(\n",
    "        model_fn=cnn_model_fn,\n",
    "        params=model_params,\n",
    "        model_dir=\"/tmp/mnist_convnet_model\")\n",
    "\n",
    "    # Train the model\n",
    "    if mode == 'train':\n",
    "        train_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "            x={\"x\": train_data},\n",
    "            y=train_labels,\n",
    "            batch_size=100,\n",
    "            num_epochs=10,\n",
    "            shuffle=True)\n",
    "        mnist_classifier.train(\n",
    "            input_fn=train_input_fn)\n",
    "    elif mode == 'predict':\n",
    "        predict_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "            x={\"x\": eval_data},\n",
    "            num_epochs=1,\n",
    "            shuffle=False)\n",
    "        preds = mnist_classifier.predict(\n",
    "            input_fn=predict_input_fn)\n",
    "        return np.array([p for p in preds])\n",
    "    elif mode == 'eval':\n",
    "        # Evaluate the model and print results\n",
    "        eval_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "            x={\"x\": eval_data},\n",
    "            y=eval_labels,\n",
    "            num_epochs=1,\n",
    "            shuffle=False)\n",
    "        eval_results = mnist_classifier.evaluate(input_fn=eval_input_fn)\n",
    "        print(eval_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST-data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST-data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST-data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST-data/t10k-labels-idx1-ubyte.gz\n",
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_log_step_count_steps': 100, '_save_checkpoints_secs': 600, '_model_dir': '/tmp/mnist_convnet_model', '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_tf_random_seed': 1, '_session_config': None}\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/mnist_convnet_model/model.ckpt-5500\n",
      "INFO:tensorflow:Saving checkpoints for 5501 into /tmp/mnist_convnet_model/model.ckpt.\n",
      "INFO:tensorflow:step = 5501, loss = 0.323929\n",
      "INFO:tensorflow:global_step/sec: 149.584\n",
      "INFO:tensorflow:step = 5601, loss = 0.397762 (0.669 sec)\n",
      "INFO:tensorflow:global_step/sec: 155.908\n",
      "INFO:tensorflow:step = 5701, loss = 0.350399 (0.641 sec)\n",
      "INFO:tensorflow:global_step/sec: 154.449\n",
      "INFO:tensorflow:step = 5801, loss = 0.349167 (0.647 sec)\n",
      "INFO:tensorflow:global_step/sec: 155.557\n",
      "INFO:tensorflow:step = 5901, loss = 0.288345 (0.643 sec)\n",
      "INFO:tensorflow:global_step/sec: 158.088\n",
      "INFO:tensorflow:step = 6001, loss = 0.349776 (0.633 sec)\n",
      "INFO:tensorflow:global_step/sec: 154.335\n",
      "INFO:tensorflow:step = 6101, loss = 0.331582 (0.648 sec)\n",
      "INFO:tensorflow:global_step/sec: 154.266\n",
      "INFO:tensorflow:step = 6201, loss = 0.284987 (0.648 sec)\n",
      "INFO:tensorflow:global_step/sec: 156.664\n",
      "INFO:tensorflow:step = 6301, loss = 0.268688 (0.638 sec)\n",
      "INFO:tensorflow:global_step/sec: 154.731\n",
      "INFO:tensorflow:step = 6401, loss = 0.274514 (0.646 sec)\n",
      "INFO:tensorflow:global_step/sec: 154.691\n",
      "INFO:tensorflow:step = 6501, loss = 0.323706 (0.647 sec)\n",
      "INFO:tensorflow:global_step/sec: 157.601\n",
      "INFO:tensorflow:step = 6601, loss = 0.253169 (0.634 sec)\n",
      "INFO:tensorflow:global_step/sec: 157.179\n",
      "INFO:tensorflow:step = 6701, loss = 0.403806 (0.637 sec)\n",
      "INFO:tensorflow:global_step/sec: 156.674\n",
      "INFO:tensorflow:step = 6801, loss = 0.237176 (0.638 sec)\n",
      "INFO:tensorflow:global_step/sec: 155.072\n",
      "INFO:tensorflow:step = 6901, loss = 0.286503 (0.645 sec)\n",
      "INFO:tensorflow:global_step/sec: 154.219\n",
      "INFO:tensorflow:step = 7001, loss = 0.351238 (0.649 sec)\n",
      "INFO:tensorflow:global_step/sec: 155.665\n",
      "INFO:tensorflow:step = 7101, loss = 0.328372 (0.642 sec)\n",
      "INFO:tensorflow:global_step/sec: 152.601\n",
      "INFO:tensorflow:step = 7201, loss = 0.251898 (0.655 sec)\n",
      "INFO:tensorflow:global_step/sec: 150.05\n",
      "INFO:tensorflow:step = 7301, loss = 0.21798 (0.667 sec)\n",
      "INFO:tensorflow:global_step/sec: 153.545\n",
      "INFO:tensorflow:step = 7401, loss = 0.254036 (0.651 sec)\n",
      "INFO:tensorflow:global_step/sec: 153.158\n",
      "INFO:tensorflow:step = 7501, loss = 0.245151 (0.653 sec)\n",
      "INFO:tensorflow:global_step/sec: 153.23\n",
      "INFO:tensorflow:step = 7601, loss = 0.249227 (0.653 sec)\n",
      "INFO:tensorflow:global_step/sec: 155.125\n",
      "INFO:tensorflow:step = 7701, loss = 0.153396 (0.644 sec)\n",
      "INFO:tensorflow:global_step/sec: 151.829\n",
      "INFO:tensorflow:step = 7801, loss = 0.277186 (0.659 sec)\n",
      "INFO:tensorflow:global_step/sec: 158.042\n",
      "INFO:tensorflow:step = 7901, loss = 0.214134 (0.633 sec)\n",
      "INFO:tensorflow:global_step/sec: 148.716\n",
      "INFO:tensorflow:step = 8001, loss = 0.290546 (0.673 sec)\n",
      "INFO:tensorflow:global_step/sec: 146.06\n",
      "INFO:tensorflow:step = 8101, loss = 0.229671 (0.685 sec)\n",
      "INFO:tensorflow:global_step/sec: 155.56\n",
      "INFO:tensorflow:step = 8201, loss = 0.303403 (0.643 sec)\n",
      "INFO:tensorflow:global_step/sec: 151.667\n",
      "INFO:tensorflow:step = 8301, loss = 0.321564 (0.659 sec)\n",
      "INFO:tensorflow:global_step/sec: 154.052\n",
      "INFO:tensorflow:step = 8401, loss = 0.239201 (0.649 sec)\n",
      "INFO:tensorflow:global_step/sec: 151.952\n",
      "INFO:tensorflow:step = 8501, loss = 0.158346 (0.658 sec)\n",
      "INFO:tensorflow:global_step/sec: 135.318\n",
      "INFO:tensorflow:step = 8601, loss = 0.128319 (0.739 sec)\n",
      "INFO:tensorflow:global_step/sec: 153.216\n",
      "INFO:tensorflow:step = 8701, loss = 0.206988 (0.653 sec)\n",
      "INFO:tensorflow:global_step/sec: 151.869\n",
      "INFO:tensorflow:step = 8801, loss = 0.325772 (0.659 sec)\n",
      "INFO:tensorflow:global_step/sec: 154.154\n",
      "INFO:tensorflow:step = 8901, loss = 0.195797 (0.648 sec)\n",
      "INFO:tensorflow:global_step/sec: 150.211\n",
      "INFO:tensorflow:step = 9001, loss = 0.248845 (0.666 sec)\n",
      "INFO:tensorflow:global_step/sec: 156.024\n",
      "INFO:tensorflow:step = 9101, loss = 0.190223 (0.641 sec)\n",
      "INFO:tensorflow:global_step/sec: 155.797\n",
      "INFO:tensorflow:step = 9201, loss = 0.329512 (0.642 sec)\n",
      "INFO:tensorflow:global_step/sec: 155.061\n",
      "INFO:tensorflow:step = 9301, loss = 0.275529 (0.645 sec)\n",
      "INFO:tensorflow:global_step/sec: 147.373\n",
      "INFO:tensorflow:step = 9401, loss = 0.301226 (0.679 sec)\n",
      "INFO:tensorflow:global_step/sec: 139.796\n",
      "INFO:tensorflow:step = 9501, loss = 0.250081 (0.716 sec)\n",
      "INFO:tensorflow:global_step/sec: 155.932\n",
      "INFO:tensorflow:step = 9601, loss = 0.173537 (0.641 sec)\n",
      "INFO:tensorflow:global_step/sec: 139.579\n",
      "INFO:tensorflow:step = 9701, loss = 0.20533 (0.716 sec)\n",
      "INFO:tensorflow:global_step/sec: 157.402\n",
      "INFO:tensorflow:step = 9801, loss = 0.201137 (0.635 sec)\n",
      "INFO:tensorflow:global_step/sec: 157.043\n",
      "INFO:tensorflow:step = 9901, loss = 0.270502 (0.637 sec)\n",
      "INFO:tensorflow:global_step/sec: 156.534\n",
      "INFO:tensorflow:step = 10001, loss = 0.271224 (0.639 sec)\n",
      "INFO:tensorflow:global_step/sec: 156.841\n",
      "INFO:tensorflow:step = 10101, loss = 0.32557 (0.637 sec)\n",
      "INFO:tensorflow:global_step/sec: 157.131\n",
      "INFO:tensorflow:step = 10201, loss = 0.129518 (0.638 sec)\n",
      "INFO:tensorflow:global_step/sec: 153.653\n",
      "INFO:tensorflow:step = 10301, loss = 0.283362 (0.650 sec)\n",
      "INFO:tensorflow:global_step/sec: 153.616\n",
      "INFO:tensorflow:step = 10401, loss = 0.268937 (0.651 sec)\n",
      "INFO:tensorflow:global_step/sec: 158.479\n",
      "INFO:tensorflow:step = 10501, loss = 0.220199 (0.631 sec)\n",
      "INFO:tensorflow:global_step/sec: 154.755\n",
      "INFO:tensorflow:step = 10601, loss = 0.303878 (0.646 sec)\n",
      "INFO:tensorflow:global_step/sec: 140.74\n",
      "INFO:tensorflow:step = 10701, loss = 0.0993388 (0.711 sec)\n",
      "INFO:tensorflow:global_step/sec: 147.965\n",
      "INFO:tensorflow:step = 10801, loss = 0.248866 (0.676 sec)\n",
      "INFO:tensorflow:global_step/sec: 150.917\n",
      "INFO:tensorflow:step = 10901, loss = 0.170337 (0.662 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 11000 into /tmp/mnist_convnet_model/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.209103.\n"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST-data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST-data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST-data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST-data/t10k-labels-idx1-ubyte.gz\n",
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_log_step_count_steps': 100, '_save_checkpoints_secs': 600, '_model_dir': '/tmp/mnist_convnet_model', '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_tf_random_seed': 1, '_session_config': None}\n",
      "INFO:tensorflow:Starting evaluation at 2018-01-05-04:34:30\n",
      "INFO:tensorflow:Restoring parameters from /tmp/mnist_convnet_model/model.ckpt-11000\n",
      "INFO:tensorflow:Finished evaluation at 2018-01-05-04:34:30\n",
      "INFO:tensorflow:Saving dict for global step 11000: accuracy = 0.9538, global_step = 11000, loss = 0.160787\n",
      "{'global_step': 11000, 'accuracy': 0.95380002, 'loss': 0.16078672}\n"
     ]
    }
   ],
   "source": [
    "main(mode='eval')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST-data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST-data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST-data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST-data/t10k-labels-idx1-ubyte.gz\n",
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_log_step_count_steps': 100, '_save_checkpoints_secs': 600, '_model_dir': '/tmp/mnist_convnet_model', '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_tf_random_seed': 1, '_session_config': None}\n",
      "INFO:tensorflow:Restoring parameters from /tmp/mnist_convnet_model/model.ckpt-11000\n"
     ]
    }
   ],
   "source": [
    "preds = main(mode='predict')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'classes': 7,\n",
       " 'probabilities': array([  3.51151743e-06,   4.31621999e-07,   1.09308103e-05,\n",
       "          2.82746973e-04,   7.02955447e-07,   2.08513757e-06,\n",
       "          7.55197416e-09,   9.99232888e-01,   4.67267591e-06,\n",
       "          4.62032418e-04], dtype=float32)}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
